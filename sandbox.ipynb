{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv .env.hf-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "state_dict_legacy = torch.load(\"/home/antoine/models/nereus/dino_resnet50/resnet50.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "with torch.no_grad():\n",
    "    resnet50 = torchvision.models.resnet50(weights=None)\n",
    "    resnet50.fc = torch.nn.Identity()\n",
    "    \n",
    "    conv1 = resnet50.conv1\n",
    "    new_conv1 = torch.nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=conv1.out_channels,\n",
    "                kernel_size=conv1.kernel_size,\n",
    "                stride=conv1.stride,\n",
    "                padding=conv1.padding,\n",
    "                bias=(conv1.bias is not None)\n",
    "            )\n",
    "    \n",
    "    new_conv1.weight = torch.nn.Parameter(conv1.weight.sum(dim=1, keepdim=True))\n",
    "\n",
    "    resnet50.conv1 = new_conv1\n",
    "\n",
    "resnet50.eval()\n",
    "\n",
    "state_dict = {}\n",
    "\n",
    "trad = {\n",
    "    \"0\": \"conv1\",\n",
    "    \"1\": \"bn1\",\n",
    "    \"4\": \"layer1\",\n",
    "    \"5\": \"layer2\",\n",
    "    \"6\": \"layer3\",\n",
    "    \"7\": \"layer4\",\n",
    "}\n",
    "\n",
    "for k, v in state_dict_legacy.items():\n",
    "    if k.startswith(\"student_backbone.backbone.\"):\n",
    "        k_new = k.removeprefix(\"student_backbone.backbone.\")\n",
    "        for kk, vv in trad.items():\n",
    "            if k_new.startswith(kk):\n",
    "                k_new = k_new.replace(kk, vv, 1)\n",
    "                break\n",
    "        state_dict[k_new] = v\n",
    "\n",
    "resnet50.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type (var_name):depth-idx)                  Output Shape              Param #\n",
       "====================================================================================================\n",
       "ResNet (ResNet)                                    [1, 2048]                 --\n",
       "├─Conv2d (conv1): 1-1                              [1, 64, 128, 128]         3,136\n",
       "├─BatchNorm2d (bn1): 1-2                           [1, 64, 128, 128]         128\n",
       "├─ReLU (relu): 1-3                                 [1, 64, 128, 128]         --\n",
       "├─MaxPool2d (maxpool): 1-4                         [1, 64, 64, 64]           --\n",
       "├─Sequential (layer1): 1-5                         [1, 256, 64, 64]          --\n",
       "│    └─Bottleneck (0): 2-1                         [1, 256, 64, 64]          --\n",
       "│    │    └─Conv2d (conv1): 3-1                    [1, 64, 64, 64]           4,096\n",
       "│    │    └─BatchNorm2d (bn1): 3-2                 [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU (relu): 3-3                       [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d (conv2): 3-4                    [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d (bn2): 3-5                 [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU (relu): 3-6                       [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d (conv3): 3-7                    [1, 256, 64, 64]          16,384\n",
       "│    │    └─BatchNorm2d (bn3): 3-8                 [1, 256, 64, 64]          512\n",
       "│    │    └─Sequential (downsample): 3-9           [1, 256, 64, 64]          --\n",
       "│    │    │    └─Conv2d (0): 4-1                   [1, 256, 64, 64]          16,384\n",
       "│    │    │    └─BatchNorm2d (1): 4-2              [1, 256, 64, 64]          512\n",
       "│    │    └─ReLU (relu): 3-10                      [1, 256, 64, 64]          --\n",
       "│    └─Bottleneck (1): 2-2                         [1, 256, 64, 64]          --\n",
       "│    │    └─Conv2d (conv1): 3-11                   [1, 64, 64, 64]           16,384\n",
       "│    │    └─BatchNorm2d (bn1): 3-12                [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU (relu): 3-13                      [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d (conv2): 3-14                   [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d (bn2): 3-15                [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU (relu): 3-16                      [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d (conv3): 3-17                   [1, 256, 64, 64]          16,384\n",
       "│    │    └─BatchNorm2d (bn3): 3-18                [1, 256, 64, 64]          512\n",
       "│    │    └─ReLU (relu): 3-19                      [1, 256, 64, 64]          --\n",
       "│    └─Bottleneck (2): 2-3                         [1, 256, 64, 64]          --\n",
       "│    │    └─Conv2d (conv1): 3-20                   [1, 64, 64, 64]           16,384\n",
       "│    │    └─BatchNorm2d (bn1): 3-21                [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU (relu): 3-22                      [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d (conv2): 3-23                   [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d (bn2): 3-24                [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU (relu): 3-25                      [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d (conv3): 3-26                   [1, 256, 64, 64]          16,384\n",
       "│    │    └─BatchNorm2d (bn3): 3-27                [1, 256, 64, 64]          512\n",
       "│    │    └─ReLU (relu): 3-28                      [1, 256, 64, 64]          --\n",
       "├─Sequential (layer2): 1-6                         [1, 512, 32, 32]          --\n",
       "│    └─Bottleneck (0): 2-4                         [1, 512, 32, 32]          --\n",
       "│    │    └─Conv2d (conv1): 3-29                   [1, 128, 64, 64]          32,768\n",
       "│    │    └─BatchNorm2d (bn1): 3-30                [1, 128, 64, 64]          256\n",
       "│    │    └─ReLU (relu): 3-31                      [1, 128, 64, 64]          --\n",
       "│    │    └─Conv2d (conv2): 3-32                   [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d (bn2): 3-33                [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU (relu): 3-34                      [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d (conv3): 3-35                   [1, 512, 32, 32]          65,536\n",
       "│    │    └─BatchNorm2d (bn3): 3-36                [1, 512, 32, 32]          1,024\n",
       "│    │    └─Sequential (downsample): 3-37          [1, 512, 32, 32]          --\n",
       "│    │    │    └─Conv2d (0): 4-3                   [1, 512, 32, 32]          131,072\n",
       "│    │    │    └─BatchNorm2d (1): 4-4              [1, 512, 32, 32]          1,024\n",
       "│    │    └─ReLU (relu): 3-38                      [1, 512, 32, 32]          --\n",
       "│    └─Bottleneck (1): 2-5                         [1, 512, 32, 32]          --\n",
       "│    │    └─Conv2d (conv1): 3-39                   [1, 128, 32, 32]          65,536\n",
       "│    │    └─BatchNorm2d (bn1): 3-40                [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU (relu): 3-41                      [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d (conv2): 3-42                   [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d (bn2): 3-43                [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU (relu): 3-44                      [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d (conv3): 3-45                   [1, 512, 32, 32]          65,536\n",
       "│    │    └─BatchNorm2d (bn3): 3-46                [1, 512, 32, 32]          1,024\n",
       "│    │    └─ReLU (relu): 3-47                      [1, 512, 32, 32]          --\n",
       "│    └─Bottleneck (2): 2-6                         [1, 512, 32, 32]          --\n",
       "│    │    └─Conv2d (conv1): 3-48                   [1, 128, 32, 32]          65,536\n",
       "│    │    └─BatchNorm2d (bn1): 3-49                [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU (relu): 3-50                      [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d (conv2): 3-51                   [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d (bn2): 3-52                [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU (relu): 3-53                      [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d (conv3): 3-54                   [1, 512, 32, 32]          65,536\n",
       "│    │    └─BatchNorm2d (bn3): 3-55                [1, 512, 32, 32]          1,024\n",
       "│    │    └─ReLU (relu): 3-56                      [1, 512, 32, 32]          --\n",
       "│    └─Bottleneck (3): 2-7                         [1, 512, 32, 32]          --\n",
       "│    │    └─Conv2d (conv1): 3-57                   [1, 128, 32, 32]          65,536\n",
       "│    │    └─BatchNorm2d (bn1): 3-58                [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU (relu): 3-59                      [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d (conv2): 3-60                   [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d (bn2): 3-61                [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU (relu): 3-62                      [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d (conv3): 3-63                   [1, 512, 32, 32]          65,536\n",
       "│    │    └─BatchNorm2d (bn3): 3-64                [1, 512, 32, 32]          1,024\n",
       "│    │    └─ReLU (relu): 3-65                      [1, 512, 32, 32]          --\n",
       "├─Sequential (layer3): 1-7                         [1, 1024, 16, 16]         --\n",
       "│    └─Bottleneck (0): 2-8                         [1, 1024, 16, 16]         --\n",
       "│    │    └─Conv2d (conv1): 3-66                   [1, 256, 32, 32]          131,072\n",
       "│    │    └─BatchNorm2d (bn1): 3-67                [1, 256, 32, 32]          512\n",
       "│    │    └─ReLU (relu): 3-68                      [1, 256, 32, 32]          --\n",
       "│    │    └─Conv2d (conv2): 3-69                   [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d (bn2): 3-70                [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-71                      [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv3): 3-72                   [1, 1024, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d (bn3): 3-73                [1, 1024, 16, 16]         2,048\n",
       "│    │    └─Sequential (downsample): 3-74          [1, 1024, 16, 16]         --\n",
       "│    │    │    └─Conv2d (0): 4-5                   [1, 1024, 16, 16]         524,288\n",
       "│    │    │    └─BatchNorm2d (1): 4-6              [1, 1024, 16, 16]         2,048\n",
       "│    │    └─ReLU (relu): 3-75                      [1, 1024, 16, 16]         --\n",
       "│    └─Bottleneck (1): 2-9                         [1, 1024, 16, 16]         --\n",
       "│    │    └─Conv2d (conv1): 3-76                   [1, 256, 16, 16]          262,144\n",
       "│    │    └─BatchNorm2d (bn1): 3-77                [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-78                      [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv2): 3-79                   [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d (bn2): 3-80                [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-81                      [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv3): 3-82                   [1, 1024, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d (bn3): 3-83                [1, 1024, 16, 16]         2,048\n",
       "│    │    └─ReLU (relu): 3-84                      [1, 1024, 16, 16]         --\n",
       "│    └─Bottleneck (2): 2-10                        [1, 1024, 16, 16]         --\n",
       "│    │    └─Conv2d (conv1): 3-85                   [1, 256, 16, 16]          262,144\n",
       "│    │    └─BatchNorm2d (bn1): 3-86                [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-87                      [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv2): 3-88                   [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d (bn2): 3-89                [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-90                      [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv3): 3-91                   [1, 1024, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d (bn3): 3-92                [1, 1024, 16, 16]         2,048\n",
       "│    │    └─ReLU (relu): 3-93                      [1, 1024, 16, 16]         --\n",
       "│    └─Bottleneck (3): 2-11                        [1, 1024, 16, 16]         --\n",
       "│    │    └─Conv2d (conv1): 3-94                   [1, 256, 16, 16]          262,144\n",
       "│    │    └─BatchNorm2d (bn1): 3-95                [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-96                      [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv2): 3-97                   [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d (bn2): 3-98                [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-99                      [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv3): 3-100                  [1, 1024, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d (bn3): 3-101               [1, 1024, 16, 16]         2,048\n",
       "│    │    └─ReLU (relu): 3-102                     [1, 1024, 16, 16]         --\n",
       "│    └─Bottleneck (4): 2-12                        [1, 1024, 16, 16]         --\n",
       "│    │    └─Conv2d (conv1): 3-103                  [1, 256, 16, 16]          262,144\n",
       "│    │    └─BatchNorm2d (bn1): 3-104               [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-105                     [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv2): 3-106                  [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d (bn2): 3-107               [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-108                     [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv3): 3-109                  [1, 1024, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d (bn3): 3-110               [1, 1024, 16, 16]         2,048\n",
       "│    │    └─ReLU (relu): 3-111                     [1, 1024, 16, 16]         --\n",
       "│    └─Bottleneck (5): 2-13                        [1, 1024, 16, 16]         --\n",
       "│    │    └─Conv2d (conv1): 3-112                  [1, 256, 16, 16]          262,144\n",
       "│    │    └─BatchNorm2d (bn1): 3-113               [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-114                     [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv2): 3-115                  [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d (bn2): 3-116               [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU (relu): 3-117                     [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (conv3): 3-118                  [1, 1024, 16, 16]         262,144\n",
       "│    │    └─BatchNorm2d (bn3): 3-119               [1, 1024, 16, 16]         2,048\n",
       "│    │    └─ReLU (relu): 3-120                     [1, 1024, 16, 16]         --\n",
       "├─Sequential (layer4): 1-8                         [1, 2048, 8, 8]           --\n",
       "│    └─Bottleneck (0): 2-14                        [1, 2048, 8, 8]           --\n",
       "│    │    └─Conv2d (conv1): 3-121                  [1, 512, 16, 16]          524,288\n",
       "│    │    └─BatchNorm2d (bn1): 3-122               [1, 512, 16, 16]          1,024\n",
       "│    │    └─ReLU (relu): 3-123                     [1, 512, 16, 16]          --\n",
       "│    │    └─Conv2d (conv2): 3-124                  [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d (bn2): 3-125               [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU (relu): 3-126                     [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d (conv3): 3-127                  [1, 2048, 8, 8]           1,048,576\n",
       "│    │    └─BatchNorm2d (bn3): 3-128               [1, 2048, 8, 8]           4,096\n",
       "│    │    └─Sequential (downsample): 3-129         [1, 2048, 8, 8]           --\n",
       "│    │    │    └─Conv2d (0): 4-7                   [1, 2048, 8, 8]           2,097,152\n",
       "│    │    │    └─BatchNorm2d (1): 4-8              [1, 2048, 8, 8]           4,096\n",
       "│    │    └─ReLU (relu): 3-130                     [1, 2048, 8, 8]           --\n",
       "│    └─Bottleneck (1): 2-15                        [1, 2048, 8, 8]           --\n",
       "│    │    └─Conv2d (conv1): 3-131                  [1, 512, 8, 8]            1,048,576\n",
       "│    │    └─BatchNorm2d (bn1): 3-132               [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU (relu): 3-133                     [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d (conv2): 3-134                  [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d (bn2): 3-135               [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU (relu): 3-136                     [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d (conv3): 3-137                  [1, 2048, 8, 8]           1,048,576\n",
       "│    │    └─BatchNorm2d (bn3): 3-138               [1, 2048, 8, 8]           4,096\n",
       "│    │    └─ReLU (relu): 3-139                     [1, 2048, 8, 8]           --\n",
       "│    └─Bottleneck (2): 2-16                        [1, 2048, 8, 8]           --\n",
       "│    │    └─Conv2d (conv1): 3-140                  [1, 512, 8, 8]            1,048,576\n",
       "│    │    └─BatchNorm2d (bn1): 3-141               [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU (relu): 3-142                     [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d (conv2): 3-143                  [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d (bn2): 3-144               [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU (relu): 3-145                     [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d (conv3): 3-146                  [1, 2048, 8, 8]           1,048,576\n",
       "│    │    └─BatchNorm2d (bn3): 3-147               [1, 2048, 8, 8]           4,096\n",
       "│    │    └─ReLU (relu): 3-148                     [1, 2048, 8, 8]           --\n",
       "├─AdaptiveAvgPool2d (avgpool): 1-9                 [1, 2048, 1, 1]           --\n",
       "├─Identity (fc): 1-10                              [1, 2048]                 --\n",
       "====================================================================================================\n",
       "Total params: 23,501,760\n",
       "Trainable params: 23,501,760\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.24\n",
       "====================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 232.26\n",
       "Params size (MB): 94.01\n",
       "Estimated Total Size (MB): 326.53\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(resnet50, (1, 1, 256, 256), device=\"cpu\", depth=10, row_settings=[\"var_names\", \"depth\"], mode=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(resnet50.state_dict(), \"resnet50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                                           Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "ResNetModel (ResNetModel)                                                   [1, 2048, 1, 1]           --\n",
       "├─ResNetEmbeddings (embedder): 1-1                                          [1, 64, 64, 64]           --\n",
       "│    └─ResNetConvLayer (embedder): 2-1                                      [1, 64, 128, 128]         --\n",
       "│    │    └─Conv2d (convolution): 3-1                                       [1, 64, 128, 128]         3,136\n",
       "│    │    └─BatchNorm2d (normalization): 3-2                                [1, 64, 128, 128]         128\n",
       "│    │    └─ReLU (activation): 3-3                                          [1, 64, 128, 128]         --\n",
       "│    └─MaxPool2d (pooler): 2-2                                              [1, 64, 64, 64]           --\n",
       "├─ResNetEncoder (encoder): 1-2                                              [1, 2048, 8, 8]           --\n",
       "│    └─ModuleList (stages): 2-3                                             --                        --\n",
       "│    │    └─ResNetStage (0): 3-4                                            [1, 256, 64, 64]          --\n",
       "│    │    │    └─Sequential (layers): 4-1                                   --                        --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (0): 5-1                        [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-1                          [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-1                    [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-1              [1, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-2       [1, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-3                 [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-2                    [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-4              [1, 64, 64, 64]           36,864\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-5       [1, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-6                 [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-3                    [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-7              [1, 256, 64, 64]          16,384\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-8       [1, 256, 64, 64]          512\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-9             [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─ResNetShortCut (shortcut): 6-2                   [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    └─Conv2d (convolution): 7-4                   [1, 256, 64, 64]          16,384\n",
       "│    │    │    │    │    │    └─BatchNorm2d (normalization): 7-5            [1, 256, 64, 64]          512\n",
       "│    │    │    │    │    └─ReLU (activation): 6-3                           [1, 256, 64, 64]          --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (1): 5-2                        [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-4                          [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-6                    [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-10             [1, 64, 64, 64]           16,384\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-11      [1, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-12                [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-7                    [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-13             [1, 64, 64, 64]           36,864\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-14      [1, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-15                [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-8                    [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-16             [1, 256, 64, 64]          16,384\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-17      [1, 256, 64, 64]          512\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-18            [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-5                         [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-6                           [1, 256, 64, 64]          --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (2): 5-3                        [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-7                          [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-9                    [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-19             [1, 64, 64, 64]           16,384\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-20      [1, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-21                [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-10                   [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-22             [1, 64, 64, 64]           36,864\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-23      [1, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-24                [1, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-11                   [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-25             [1, 256, 64, 64]          16,384\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-26      [1, 256, 64, 64]          512\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-27            [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-8                         [1, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-9                           [1, 256, 64, 64]          --\n",
       "│    │    └─ResNetStage (1): 3-5                                            [1, 512, 32, 32]          --\n",
       "│    │    │    └─Sequential (layers): 4-2                                   --                        --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (0): 5-4                        [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-10                         [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-12                   [1, 128, 64, 64]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-28             [1, 128, 64, 64]          32,768\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-29      [1, 128, 64, 64]          256\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-30                [1, 128, 64, 64]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-13                   [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-31             [1, 128, 32, 32]          147,456\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-32      [1, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-33                [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-14                   [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-34             [1, 512, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-35      [1, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-36            [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─ResNetShortCut (shortcut): 6-11                  [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    └─Conv2d (convolution): 7-15                  [1, 512, 32, 32]          131,072\n",
       "│    │    │    │    │    │    └─BatchNorm2d (normalization): 7-16           [1, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    └─ReLU (activation): 6-12                          [1, 512, 32, 32]          --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (1): 5-5                        [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-13                         [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-17                   [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-37             [1, 128, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-38      [1, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-39                [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-18                   [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-40             [1, 128, 32, 32]          147,456\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-41      [1, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-42                [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-19                   [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-43             [1, 512, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-44      [1, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-45            [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-14                        [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-15                          [1, 512, 32, 32]          --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (2): 5-6                        [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-16                         [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-20                   [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-46             [1, 128, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-47      [1, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-48                [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-21                   [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-49             [1, 128, 32, 32]          147,456\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-50      [1, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-51                [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-22                   [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-52             [1, 512, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-53      [1, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-54            [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-17                        [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-18                          [1, 512, 32, 32]          --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (3): 5-7                        [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-19                         [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-23                   [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-55             [1, 128, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-56      [1, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-57                [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-24                   [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-58             [1, 128, 32, 32]          147,456\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-59      [1, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-60                [1, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-25                   [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-61             [1, 512, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-62      [1, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-63            [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-20                        [1, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-21                          [1, 512, 32, 32]          --\n",
       "│    │    └─ResNetStage (2): 3-6                                            [1, 1024, 16, 16]         --\n",
       "│    │    │    └─Sequential (layers): 4-3                                   --                        --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (0): 5-8                        [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-22                         [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-26                   [1, 256, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-64             [1, 256, 32, 32]          131,072\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-65      [1, 256, 32, 32]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-66                [1, 256, 32, 32]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-27                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-67             [1, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-68      [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-69                [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-28                   [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-70             [1, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-71      [1, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-72            [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─ResNetShortCut (shortcut): 6-23                  [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─Conv2d (convolution): 7-29                  [1, 1024, 16, 16]         524,288\n",
       "│    │    │    │    │    │    └─BatchNorm2d (normalization): 7-30           [1, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    └─ReLU (activation): 6-24                          [1, 1024, 16, 16]         --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (1): 5-9                        [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-25                         [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-31                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-73             [1, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-74      [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-75                [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-32                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-76             [1, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-77      [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-78                [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-33                   [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-79             [1, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-80      [1, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-81            [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-26                        [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-27                          [1, 1024, 16, 16]         --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (2): 5-10                       [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-28                         [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-34                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-82             [1, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-83      [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-84                [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-35                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-85             [1, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-86      [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-87                [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-36                   [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-88             [1, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-89      [1, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-90            [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-29                        [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-30                          [1, 1024, 16, 16]         --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (3): 5-11                       [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-31                         [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-37                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-91             [1, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-92      [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-93                [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-38                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-94             [1, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-95      [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-96                [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-39                   [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-97             [1, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-98      [1, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-99            [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-32                        [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-33                          [1, 1024, 16, 16]         --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (4): 5-12                       [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-34                         [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-40                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-100            [1, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-101     [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-102               [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-41                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-103            [1, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-104     [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-105               [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-42                   [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-106            [1, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-107     [1, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-108           [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-35                        [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-36                          [1, 1024, 16, 16]         --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (5): 5-13                       [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-37                         [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-43                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-109            [1, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-110     [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-111               [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-44                   [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-112            [1, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-113     [1, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-114               [1, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-45                   [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-115            [1, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-116     [1, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-117           [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-38                        [1, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-39                          [1, 1024, 16, 16]         --\n",
       "│    │    └─ResNetStage (3): 3-7                                            [1, 2048, 8, 8]           --\n",
       "│    │    │    └─Sequential (layers): 4-4                                   --                        --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (0): 5-14                       [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-40                         [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-46                   [1, 512, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-118            [1, 512, 16, 16]          524,288\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-119     [1, 512, 16, 16]          1,024\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-120               [1, 512, 16, 16]          --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-47                   [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-121            [1, 512, 8, 8]            2,359,296\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-122     [1, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-123               [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-48                   [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-124            [1, 2048, 8, 8]           1,048,576\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-125     [1, 2048, 8, 8]           4,096\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-126           [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    └─ResNetShortCut (shortcut): 6-41                  [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    └─Conv2d (convolution): 7-49                  [1, 2048, 8, 8]           2,097,152\n",
       "│    │    │    │    │    │    └─BatchNorm2d (normalization): 7-50           [1, 2048, 8, 8]           4,096\n",
       "│    │    │    │    │    └─ReLU (activation): 6-42                          [1, 2048, 8, 8]           --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (1): 5-15                       [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-43                         [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-51                   [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-127            [1, 512, 8, 8]            1,048,576\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-128     [1, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-129               [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-52                   [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-130            [1, 512, 8, 8]            2,359,296\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-131     [1, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-132               [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-53                   [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-133            [1, 2048, 8, 8]           1,048,576\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-134     [1, 2048, 8, 8]           4,096\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-135           [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-44                        [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-45                          [1, 2048, 8, 8]           --\n",
       "│    │    │    │    └─ResNetBottleNeckLayer (2): 5-16                       [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    └─Sequential (layer): 6-46                         [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (0): 7-54                   [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-136            [1, 512, 8, 8]            1,048,576\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-137     [1, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-138               [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (1): 7-55                   [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-139            [1, 512, 8, 8]            2,359,296\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-140     [1, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    │    └─ReLU (activation): 8-141               [1, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─ResNetConvLayer (2): 7-56                   [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (convolution): 8-142            [1, 2048, 8, 8]           1,048,576\n",
       "│    │    │    │    │    │    │    └─BatchNorm2d (normalization): 8-143     [1, 2048, 8, 8]           4,096\n",
       "│    │    │    │    │    │    │    └─Identity (activation): 8-144           [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    └─Identity (shortcut): 6-47                        [1, 2048, 8, 8]           --\n",
       "│    │    │    │    │    └─ReLU (activation): 6-48                          [1, 2048, 8, 8]           --\n",
       "├─AdaptiveAvgPool2d (pooler): 1-3                                           [1, 2048, 1, 1]           --\n",
       "=============================================================================================================================\n",
       "Total params: 23,501,760\n",
       "Trainable params: 23,501,760\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.24\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 232.26\n",
       "Params size (MB): 94.01\n",
       "Estimated Total Size (MB): 326.53\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ResNetModel, ResNetConfig\n",
    "\n",
    "config_resnet = ResNetConfig(1)\n",
    "resnet50_hf = ResNetModel(config_resnet)\n",
    "\n",
    "summary(resnet50_hf, (1, 1, 256, 256), device=\"cpu\", row_settings=[\"var_names\", \"depth\"], depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name_mapping = {\n",
    "    # Initial convolution and batch norm layers\n",
    "    \"conv1.weight\": \"embedder.embedder.convolution.weight\",\n",
    "    \"bn1.weight\": \"embedder.embedder.normalization.weight\",\n",
    "    \"bn1.bias\": \"embedder.embedder.normalization.bias\",\n",
    "    \"bn1.running_mean\": \"embedder.embedder.normalization.running_mean\",\n",
    "    \"bn1.running_var\": \"embedder.embedder.normalization.running_var\",\n",
    "    \n",
    "    # Layer 1\n",
    "    \"layer1.0.conv1.weight\": \"encoder.stages.0.layers.0.layer.0.convolution.weight\",\n",
    "    \"layer1.0.bn1.weight\": \"encoder.stages.0.layers.0.layer.0.normalization.weight\",\n",
    "    \"layer1.0.bn1.bias\": \"encoder.stages.0.layers.0.layer.0.normalization.bias\",\n",
    "    \"layer1.0.bn1.running_mean\": \"encoder.stages.0.layers.0.layer.0.normalization.running_mean\",\n",
    "    \"layer1.0.bn1.running_var\": \"encoder.stages.0.layers.0.layer.0.normalization.running_var\",\n",
    "    \"layer1.0.conv2.weight\": \"encoder.stages.0.layers.0.layer.1.convolution.weight\",\n",
    "    \"layer1.0.bn2.weight\": \"encoder.stages.0.layers.0.layer.1.normalization.weight\",\n",
    "    \"layer1.0.bn2.bias\": \"encoder.stages.0.layers.0.layer.1.normalization.bias\",\n",
    "    \"layer1.0.bn2.running_mean\": \"encoder.stages.0.layers.0.layer.1.normalization.running_mean\",\n",
    "    \"layer1.0.bn2.running_var\": \"encoder.stages.0.layers.0.layer.1.normalization.running_var\",\n",
    "    \"layer1.0.conv3.weight\": \"encoder.stages.0.layers.0.layer.2.convolution.weight\",\n",
    "    \"layer1.0.bn3.weight\": \"encoder.stages.0.layers.0.layer.2.normalization.weight\",\n",
    "    \"layer1.0.bn3.bias\": \"encoder.stages.0.layers.0.layer.2.normalization.bias\",\n",
    "    \"layer1.0.bn3.running_mean\": \"encoder.stages.0.layers.0.layer.2.normalization.running_mean\",\n",
    "    \"layer1.0.bn3.running_var\": \"encoder.stages.0.layers.0.layer.2.normalization.running_var\",\n",
    "    \"layer1.0.downsample.0.weight\": \"encoder.stages.0.layers.0.shortcut.convolution.weight\",\n",
    "    \"layer1.0.downsample.1.weight\": \"encoder.stages.0.layers.0.shortcut.normalization.weight\",\n",
    "    \"layer1.0.downsample.1.bias\": \"encoder.stages.0.layers.0.shortcut.normalization.bias\",\n",
    "    \"layer1.0.downsample.1.running_mean\": \"encoder.stages.0.layers.0.shortcut.normalization.running_mean\",\n",
    "    \"layer1.0.downsample.1.running_var\": \"encoder.stages.0.layers.0.shortcut.normalization.running_var\",\n",
    "    \n",
    "    \"layer1.1.conv1.weight\": \"encoder.stages.0.layers.1.layer.0.convolution.weight\",\n",
    "    \"layer1.1.bn1.weight\": \"encoder.stages.0.layers.1.layer.0.normalization.weight\",\n",
    "    \"layer1.1.bn1.bias\": \"encoder.stages.0.layers.1.layer.0.normalization.bias\",\n",
    "    \"layer1.1.bn1.running_mean\": \"encoder.stages.0.layers.1.layer.0.normalization.running_mean\",\n",
    "    \"layer1.1.bn1.running_var\": \"encoder.stages.0.layers.1.layer.0.normalization.running_var\",\n",
    "    \"layer1.1.conv2.weight\": \"encoder.stages.0.layers.1.layer.1.convolution.weight\",\n",
    "    \"layer1.1.bn2.weight\": \"encoder.stages.0.layers.1.layer.1.normalization.weight\",\n",
    "    \"layer1.1.bn2.bias\": \"encoder.stages.0.layers.1.layer.1.normalization.bias\",\n",
    "    \"layer1.1.bn2.running_mean\": \"encoder.stages.0.layers.1.layer.1.normalization.running_mean\",\n",
    "    \"layer1.1.bn2.running_var\": \"encoder.stages.0.layers.1.layer.1.normalization.running_var\",\n",
    "    \"layer1.1.conv3.weight\": \"encoder.stages.0.layers.1.layer.2.convolution.weight\",\n",
    "    \"layer1.1.bn3.weight\": \"encoder.stages.0.layers.1.layer.2.normalization.weight\",\n",
    "    \"layer1.1.bn3.bias\": \"encoder.stages.0.layers.1.layer.2.normalization.bias\",\n",
    "    \"layer1.1.bn3.running_mean\": \"encoder.stages.0.layers.1.layer.2.normalization.running_mean\",\n",
    "    \"layer1.1.bn3.running_var\": \"encoder.stages.0.layers.1.layer.2.normalization.running_var\",\n",
    "    \n",
    "    \"layer1.2.conv1.weight\": \"encoder.stages.0.layers.2.layer.0.convolution.weight\",\n",
    "    \"layer1.2.bn1.weight\": \"encoder.stages.0.layers.2.layer.0.normalization.weight\",\n",
    "    \"layer1.2.bn1.bias\": \"encoder.stages.0.layers.2.layer.0.normalization.bias\",\n",
    "    \"layer1.2.bn1.running_mean\": \"encoder.stages.0.layers.2.layer.0.normalization.running_mean\",\n",
    "    \"layer1.2.bn1.running_var\": \"encoder.stages.0.layers.2.layer.0.normalization.running_var\",\n",
    "    \"layer1.2.conv2.weight\": \"encoder.stages.0.layers.2.layer.1.convolution.weight\",\n",
    "    \"layer1.2.bn2.weight\": \"encoder.stages.0.layers.2.layer.1.normalization.weight\",\n",
    "    \"layer1.2.bn2.bias\": \"encoder.stages.0.layers.2.layer.1.normalization.bias\",\n",
    "    \"layer1.2.bn2.running_mean\": \"encoder.stages.0.layers.2.layer.1.normalization.running_mean\",\n",
    "    \"layer1.2.bn2.running_var\": \"encoder.stages.0.layers.2.layer.1.normalization.running_var\",\n",
    "    \"layer1.2.conv3.weight\": \"encoder.stages.0.layers.2.layer.2.convolution.weight\",\n",
    "    \"layer1.2.bn3.weight\": \"encoder.stages.0.layers.2.layer.2.normalization.weight\",\n",
    "    \"layer1.2.bn3.bias\": \"encoder.stages.0.layers.2.layer.2.normalization.bias\",\n",
    "    \"layer1.2.bn3.running_mean\": \"encoder.stages.0.layers.2.layer.2.normalization.running_mean\",\n",
    "    \"layer1.2.bn3.running_var\": \"encoder.stages.0.layers.2.layer.2.normalization.running_var\",\n",
    "    \n",
    "    # Layer 2\n",
    "    \"layer2.0.conv1.weight\": \"encoder.stages.1.layers.0.layer.0.convolution.weight\",\n",
    "    \"layer2.0.bn1.weight\": \"encoder.stages.1.layers.0.layer.0.normalization.weight\",\n",
    "    \"layer2.0.bn1.bias\": \"encoder.stages.1.layers.0.layer.0.normalization.bias\",\n",
    "    \"layer2.0.bn1.running_mean\": \"encoder.stages.1.layers.0.layer.0.normalization.running_mean\",\n",
    "    \"layer2.0.bn1.running_var\": \"encoder.stages.1.layers.0.layer.0.normalization.running_var\",\n",
    "    \"layer2.0.conv2.weight\": \"encoder.stages.1.layers.0.layer.1.convolution.weight\",\n",
    "    \"layer2.0.bn2.weight\": \"encoder.stages.1.layers.0.layer.1.normalization.weight\",\n",
    "    \"layer2.0.bn2.bias\": \"encoder.stages.1.layers.0.layer.1.normalization.bias\",\n",
    "    \"layer2.0.bn2.running_mean\": \"encoder.stages.1.layers.0.layer.1.normalization.running_mean\",\n",
    "    \"layer2.0.bn2.running_var\": \"encoder.stages.1.layers.0.layer.1.normalization.running_var\",\n",
    "    \"layer2.0.conv3.weight\": \"encoder.stages.1.layers.0.layer.2.convolution.weight\",\n",
    "    \"layer2.0.bn3.weight\": \"encoder.stages.1.layers.0.layer.2.normalization.weight\",\n",
    "    \"layer2.0.bn3.bias\": \"encoder.stages.1.layers.0.layer.2.normalization.bias\",\n",
    "    \"layer2.0.bn3.running_mean\": \"encoder.stages.1.layers.0.layer.2.normalization.running_mean\",\n",
    "    \"layer2.0.bn3.running_var\": \"encoder.stages.1.layers.0.layer.2.normalization.running_var\",\n",
    "    \"layer2.0.downsample.0.weight\": \"encoder.stages.1.layers.0.shortcut.convolution.weight\",\n",
    "    \"layer2.0.downsample.1.weight\": \"encoder.stages.1.layers.0.shortcut.normalization.weight\",\n",
    "    \"layer2.0.downsample.1.bias\": \"encoder.stages.1.layers.0.shortcut.normalization.bias\",\n",
    "    \"layer2.0.downsample.1.running_mean\": \"encoder.stages.1.layers.0.shortcut.normalization.running_mean\",\n",
    "    \"layer2.0.downsample.1.running_var\": \"encoder.stages.1.layers.0.shortcut.normalization.running_var\",\n",
    "    \n",
    "    \"layer2.1.conv1.weight\": \"encoder.stages.1.layers.1.layer.0.convolution.weight\",\n",
    "    \"layer2.1.bn1.weight\": \"encoder.stages.1.layers.1.layer.0.normalization.weight\",\n",
    "    \"layer2.1.bn1.bias\": \"encoder.stages.1.layers.1.layer.0.normalization.bias\",\n",
    "    \"layer2.1.bn1.running_mean\": \"encoder.stages.1.layers.1.layer.0.normalization.running_mean\",\n",
    "    \"layer2.1.bn1.running_var\": \"encoder.stages.1.layers.1.layer.0.normalization.running_var\",\n",
    "    \"layer2.1.conv2.weight\": \"encoder.stages.1.layers.1.layer.1.convolution.weight\",\n",
    "    \"layer2.1.bn2.weight\": \"encoder.stages.1.layers.1.layer.1.normalization.weight\",\n",
    "    \"layer2.1.bn2.bias\": \"encoder.stages.1.layers.1.layer.1.normalization.bias\",\n",
    "    \"layer2.1.bn2.running_mean\": \"encoder.stages.1.layers.1.layer.1.normalization.running_mean\",\n",
    "    \"layer2.1.bn2.running_var\": \"encoder.stages.1.layers.1.layer.1.normalization.running_var\",\n",
    "    \"layer2.1.conv3.weight\": \"encoder.stages.1.layers.1.layer.2.convolution.weight\",\n",
    "    \"layer2.1.bn3.weight\": \"encoder.stages.1.layers.1.layer.2.normalization.weight\",\n",
    "    \"layer2.1.bn3.bias\": \"encoder.stages.1.layers.1.layer.2.normalization.bias\",\n",
    "    \"layer2.1.bn3.running_mean\": \"encoder.stages.1.layers.1.layer.2.normalization.running_mean\",\n",
    "    \"layer2.1.bn3.running_var\": \"encoder.stages.1.layers.1.layer.2.normalization.running_var\",\n",
    "    \n",
    "    \"layer2.2.conv1.weight\": \"encoder.stages.1.layers.2.layer.0.convolution.weight\",\n",
    "    \"layer2.2.bn1.weight\": \"encoder.stages.1.layers.2.layer.0.normalization.weight\",\n",
    "    \"layer2.2.bn1.bias\": \"encoder.stages.1.layers.2.layer.0.normalization.bias\",\n",
    "    \"layer2.2.bn1.running_mean\": \"encoder.stages.1.layers.2.layer.0.normalization.running_mean\",\n",
    "    \"layer2.2.bn1.running_var\": \"encoder.stages.1.layers.2.layer.0.normalization.running_var\",\n",
    "    \"layer2.2.conv2.weight\": \"encoder.stages.1.layers.2.layer.1.convolution.weight\",\n",
    "    \"layer2.2.bn2.weight\": \"encoder.stages.1.layers.2.layer.1.normalization.weight\",\n",
    "    \"layer2.2.bn2.bias\": \"encoder.stages.1.layers.2.layer.1.normalization.bias\",\n",
    "    \"layer2.2.bn2.running_mean\": \"encoder.stages.1.layers.2.layer.1.normalization.running_mean\",\n",
    "    \"layer2.2.bn2.running_var\": \"encoder.stages.1.layers.2.layer.1.normalization.running_var\",\n",
    "    \"layer2.2.conv3.weight\": \"encoder.stages.1.layers.2.layer.2.convolution.weight\",\n",
    "    \"layer2.2.bn3.weight\": \"encoder.stages.1.layers.2.layer.2.normalization.weight\",\n",
    "    \"layer2.2.bn3.bias\": \"encoder.stages.1.layers.2.layer.2.normalization.bias\",\n",
    "    \"layer2.2.bn3.running_mean\": \"encoder.stages.1.layers.2.layer.2.normalization.running_mean\",\n",
    "    \"layer2.2.bn3.running_var\": \"encoder.stages.1.layers.2.layer.2.normalization.running_var\",\n",
    "    \n",
    "    \"layer2.3.conv1.weight\": \"encoder.stages.1.layers.3.layer.0.convolution.weight\",\n",
    "    \"layer2.3.bn1.weight\": \"encoder.stages.1.layers.3.layer.0.normalization.weight\",\n",
    "    \"layer2.3.bn1.bias\": \"encoder.stages.1.layers.3.layer.0.normalization.bias\",\n",
    "    \"layer2.3.bn1.running_mean\": \"encoder.stages.1.layers.3.layer.0.normalization.running_mean\",\n",
    "    \"layer2.3.bn1.running_var\": \"encoder.stages.1.layers.3.layer.0.normalization.running_var\",\n",
    "    \"layer2.3.conv2.weight\": \"encoder.stages.1.layers.3.layer.1.convolution.weight\",\n",
    "    \"layer2.3.bn2.weight\": \"encoder.stages.1.layers.3.layer.1.normalization.weight\",\n",
    "    \"layer2.3.bn2.bias\": \"encoder.stages.1.layers.3.layer.1.normalization.bias\",\n",
    "    \"layer2.3.bn2.running_mean\": \"encoder.stages.1.layers.3.layer.1.normalization.running_mean\",\n",
    "    \"layer2.3.bn2.running_var\": \"encoder.stages.1.layers.3.layer.1.normalization.running_var\",\n",
    "    \"layer2.3.conv3.weight\": \"encoder.stages.1.layers.3.layer.2.convolution.weight\",\n",
    "    \"layer2.3.bn3.weight\": \"encoder.stages.1.layers.3.layer.2.normalization.weight\",\n",
    "    \"layer2.3.bn3.bias\": \"encoder.stages.1.layers.3.layer.2.normalization.bias\",\n",
    "    \"layer2.3.bn3.running_mean\": \"encoder.stages.1.layers.3.layer.2.normalization.running_mean\",\n",
    "    \"layer2.3.bn3.running_var\": \"encoder.stages.1.layers.3.layer.2.normalization.running_var\",\n",
    "    \n",
    "    # Layer 3\n",
    "    \"layer3.0.conv1.weight\": \"encoder.stages.2.layers.0.layer.0.convolution.weight\",\n",
    "    \"layer3.0.bn1.weight\": \"encoder.stages.2.layers.0.layer.0.normalization.weight\",\n",
    "    \"layer3.0.bn1.bias\": \"encoder.stages.2.layers.0.layer.0.normalization.bias\",\n",
    "    \"layer3.0.bn1.running_mean\": \"encoder.stages.2.layers.0.layer.0.normalization.running_mean\",\n",
    "    \"layer3.0.bn1.running_var\": \"encoder.stages.2.layers.0.layer.0.normalization.running_var\",\n",
    "    \"layer3.0.conv2.weight\": \"encoder.stages.2.layers.0.layer.1.convolution.weight\",\n",
    "    \"layer3.0.bn2.weight\": \"encoder.stages.2.layers.0.layer.1.normalization.weight\",\n",
    "    \"layer3.0.bn2.bias\": \"encoder.stages.2.layers.0.layer.1.normalization.bias\",\n",
    "    \"layer3.0.bn2.running_mean\": \"encoder.stages.2.layers.0.layer.1.normalization.running_mean\",\n",
    "    \"layer3.0.bn2.running_var\": \"encoder.stages.2.layers.0.layer.1.normalization.running_var\",\n",
    "    \"layer3.0.conv3.weight\": \"encoder.stages.2.layers.0.layer.2.convolution.weight\",\n",
    "    \"layer3.0.bn3.weight\": \"encoder.stages.2.layers.0.layer.2.normalization.weight\",\n",
    "    \"layer3.0.bn3.bias\": \"encoder.stages.2.layers.0.layer.2.normalization.bias\",\n",
    "    \"layer3.0.bn3.running_mean\": \"encoder.stages.2.layers.0.layer.2.normalization.running_mean\",\n",
    "    \"layer3.0.bn3.running_var\": \"encoder.stages.2.layers.0.layer.2.normalization.running_var\",\n",
    "    \"layer3.0.downsample.0.weight\": \"encoder.stages.2.layers.0.shortcut.convolution.weight\",\n",
    "    \"layer3.0.downsample.1.weight\": \"encoder.stages.2.layers.0.shortcut.normalization.weight\",\n",
    "    \"layer3.0.downsample.1.bias\": \"encoder.stages.2.layers.0.shortcut.normalization.bias\",\n",
    "    \"layer3.0.downsample.1.running_mean\": \"encoder.stages.2.layers.0.shortcut.normalization.running_mean\",\n",
    "    \"layer3.0.downsample.1.running_var\": \"encoder.stages.2.layers.0.shortcut.normalization.running_var\",\n",
    "    \n",
    "    \"layer3.1.conv1.weight\": \"encoder.stages.2.layers.1.layer.0.convolution.weight\",\n",
    "    \"layer3.1.bn1.weight\": \"encoder.stages.2.layers.1.layer.0.normalization.weight\",\n",
    "    \"layer3.1.bn1.bias\": \"encoder.stages.2.layers.1.layer.0.normalization.bias\",\n",
    "    \"layer3.1.bn1.running_mean\": \"encoder.stages.2.layers.1.layer.0.normalization.running_mean\",\n",
    "    \"layer3.1.bn1.running_var\": \"encoder.stages.2.layers.1.layer.0.normalization.running_var\",\n",
    "    \"layer3.1.conv2.weight\": \"encoder.stages.2.layers.1.layer.1.convolution.weight\",\n",
    "    \"layer3.1.bn2.weight\": \"encoder.stages.2.layers.1.layer.1.normalization.weight\",\n",
    "    \"layer3.1.bn2.bias\": \"encoder.stages.2.layers.1.layer.1.normalization.bias\",\n",
    "    \"layer3.1.bn2.running_mean\": \"encoder.stages.2.layers.1.layer.1.normalization.running_mean\",\n",
    "    \"layer3.1.bn2.running_var\": \"encoder.stages.2.layers.1.layer.1.normalization.running_var\",\n",
    "    \"layer3.1.conv3.weight\": \"encoder.stages.2.layers.1.layer.2.convolution.weight\",\n",
    "    \"layer3.1.bn3.weight\": \"encoder.stages.2.layers.1.layer.2.normalization.weight\",\n",
    "    \"layer3.1.bn3.bias\": \"encoder.stages.2.layers.1.layer.2.normalization.bias\",\n",
    "    \"layer3.1.bn3.running_mean\": \"encoder.stages.2.layers.1.layer.2.normalization.running_mean\",\n",
    "    \"layer3.1.bn3.running_var\": \"encoder.stages.2.layers.1.layer.2.normalization.running_var\",\n",
    "    \n",
    "    \"layer3.2.conv1.weight\": \"encoder.stages.2.layers.2.layer.0.convolution.weight\",\n",
    "    \"layer3.2.bn1.weight\": \"encoder.stages.2.layers.2.layer.0.normalization.weight\",\n",
    "    \"layer3.2.bn1.bias\": \"encoder.stages.2.layers.2.layer.0.normalization.bias\",\n",
    "    \"layer3.2.bn1.running_mean\": \"encoder.stages.2.layers.2.layer.0.normalization.running_mean\",\n",
    "    \"layer3.2.bn1.running_var\": \"encoder.stages.2.layers.2.layer.0.normalization.running_var\",\n",
    "    \"layer3.2.conv2.weight\": \"encoder.stages.2.layers.2.layer.1.convolution.weight\",\n",
    "    \"layer3.2.bn2.weight\": \"encoder.stages.2.layers.2.layer.1.normalization.weight\",\n",
    "    \"layer3.2.bn2.bias\": \"encoder.stages.2.layers.2.layer.1.normalization.bias\",\n",
    "    \"layer3.2.bn2.running_mean\": \"encoder.stages.2.layers.2.layer.1.normalization.running_mean\",\n",
    "    \"layer3.2.bn2.running_var\": \"encoder.stages.2.layers.2.layer.1.normalization.running_var\",\n",
    "    \"layer3.2.conv3.weight\": \"encoder.stages.2.layers.2.layer.2.convolution.weight\",\n",
    "    \"layer3.2.bn3.weight\": \"encoder.stages.2.layers.2.layer.2.normalization.weight\",\n",
    "    \"layer3.2.bn3.bias\": \"encoder.stages.2.layers.2.layer.2.normalization.bias\",\n",
    "    \"layer3.2.bn3.running_mean\": \"encoder.stages.2.layers.2.layer.2.normalization.running_mean\",\n",
    "    \"layer3.2.bn3.running_var\": \"encoder.stages.2.layers.2.layer.2.normalization.running_var\",\n",
    "    \n",
    "    \"layer3.3.conv1.weight\": \"encoder.stages.2.layers.3.layer.0.convolution.weight\",\n",
    "    \"layer3.3.bn1.weight\": \"encoder.stages.2.layers.3.layer.0.normalization.weight\",\n",
    "    \"layer3.3.bn1.bias\": \"encoder.stages.2.layers.3.layer.0.normalization.bias\",\n",
    "    \"layer3.3.bn1.running_mean\": \"encoder.stages.2.layers.3.layer.0.normalization.running_mean\",\n",
    "    \"layer3.3.bn1.running_var\": \"encoder.stages.2.layers.3.layer.0.normalization.running_var\",\n",
    "    \"layer3.3.conv2.weight\": \"encoder.stages.2.layers.3.layer.1.convolution.weight\",\n",
    "    \"layer3.3.bn2.weight\": \"encoder.stages.2.layers.3.layer.1.normalization.weight\",\n",
    "    \"layer3.3.bn2.bias\": \"encoder.stages.2.layers.3.layer.1.normalization.bias\",\n",
    "    \"layer3.3.bn2.running_mean\": \"encoder.stages.2.layers.3.layer.1.normalization.running_mean\",\n",
    "    \"layer3.3.bn2.running_var\": \"encoder.stages.2.layers.3.layer.1.normalization.running_var\",\n",
    "    \"layer3.3.conv3.weight\": \"encoder.stages.2.layers.3.layer.2.convolution.weight\",\n",
    "    \"layer3.3.bn3.weight\": \"encoder.stages.2.layers.3.layer.2.normalization.weight\",\n",
    "    \"layer3.3.bn3.bias\": \"encoder.stages.2.layers.3.layer.2.normalization.bias\",\n",
    "    \"layer3.3.bn3.running_mean\": \"encoder.stages.2.layers.3.layer.2.normalization.running_mean\",\n",
    "    \"layer3.3.bn3.running_var\": \"encoder.stages.2.layers.3.layer.2.normalization.running_var\",\n",
    "    \n",
    "    \"layer3.4.conv1.weight\": \"encoder.stages.2.layers.4.layer.0.convolution.weight\",\n",
    "    \"layer3.4.bn1.weight\": \"encoder.stages.2.layers.4.layer.0.normalization.weight\",\n",
    "    \"layer3.4.bn1.bias\": \"encoder.stages.2.layers.4.layer.0.normalization.bias\",\n",
    "    \"layer3.4.bn1.running_mean\": \"encoder.stages.2.layers.4.layer.0.normalization.running_mean\",\n",
    "    \"layer3.4.bn1.running_var\": \"encoder.stages.2.layers.4.layer.0.normalization.running_var\",\n",
    "    \"layer3.4.conv2.weight\": \"encoder.stages.2.layers.4.layer.1.convolution.weight\",\n",
    "    \"layer3.4.bn2.weight\": \"encoder.stages.2.layers.4.layer.1.normalization.weight\",\n",
    "    \"layer3.4.bn2.bias\": \"encoder.stages.2.layers.4.layer.1.normalization.bias\",\n",
    "    \"layer3.4.bn2.running_mean\": \"encoder.stages.2.layers.4.layer.1.normalization.running_mean\",\n",
    "    \"layer3.4.bn2.running_var\": \"encoder.stages.2.layers.4.layer.1.normalization.running_var\",\n",
    "    \"layer3.4.conv3.weight\": \"encoder.stages.2.layers.4.layer.2.convolution.weight\",\n",
    "    \"layer3.4.bn3.weight\": \"encoder.stages.2.layers.4.layer.2.normalization.weight\",\n",
    "    \"layer3.4.bn3.bias\": \"encoder.stages.2.layers.4.layer.2.normalization.bias\",\n",
    "    \"layer3.4.bn3.running_mean\": \"encoder.stages.2.layers.4.layer.2.normalization.running_mean\",\n",
    "    \"layer3.4.bn3.running_var\": \"encoder.stages.2.layers.4.layer.2.normalization.running_var\",\n",
    "    \n",
    "    \"layer3.5.conv1.weight\": \"encoder.stages.2.layers.5.layer.0.convolution.weight\",\n",
    "    \"layer3.5.bn1.weight\": \"encoder.stages.2.layers.5.layer.0.normalization.weight\",\n",
    "    \"layer3.5.bn1.bias\": \"encoder.stages.2.layers.5.layer.0.normalization.bias\",\n",
    "    \"layer3.5.bn1.running_mean\": \"encoder.stages.2.layers.5.layer.0.normalization.running_mean\",\n",
    "    \"layer3.5.bn1.running_var\": \"encoder.stages.2.layers.5.layer.0.normalization.running_var\",\n",
    "    \"layer3.5.conv2.weight\": \"encoder.stages.2.layers.5.layer.1.convolution.weight\",\n",
    "    \"layer3.5.bn2.weight\": \"encoder.stages.2.layers.5.layer.1.normalization.weight\",\n",
    "    \"layer3.5.bn2.bias\": \"encoder.stages.2.layers.5.layer.1.normalization.bias\",\n",
    "    \"layer3.5.bn2.running_mean\": \"encoder.stages.2.layers.5.layer.1.normalization.running_mean\",\n",
    "    \"layer3.5.bn2.running_var\": \"encoder.stages.2.layers.5.layer.1.normalization.running_var\",\n",
    "    \"layer3.5.conv3.weight\": \"encoder.stages.2.layers.5.layer.2.convolution.weight\",\n",
    "    \"layer3.5.bn3.weight\": \"encoder.stages.2.layers.5.layer.2.normalization.weight\",\n",
    "    \"layer3.5.bn3.bias\": \"encoder.stages.2.layers.5.layer.2.normalization.bias\",\n",
    "    \"layer3.5.bn3.running_mean\": \"encoder.stages.2.layers.5.layer.2.normalization.running_mean\",\n",
    "    \"layer3.5.bn3.running_var\": \"encoder.stages.2.layers.5.layer.2.normalization.running_var\",\n",
    "    \n",
    "    # Layer 4\n",
    "    \"layer4.0.conv1.weight\": \"encoder.stages.3.layers.0.layer.0.convolution.weight\",\n",
    "    \"layer4.0.bn1.weight\": \"encoder.stages.3.layers.0.layer.0.normalization.weight\",\n",
    "    \"layer4.0.bn1.bias\": \"encoder.stages.3.layers.0.layer.0.normalization.bias\",\n",
    "    \"layer4.0.bn1.running_mean\": \"encoder.stages.3.layers.0.layer.0.normalization.running_mean\",\n",
    "    \"layer4.0.bn1.running_var\": \"encoder.stages.3.layers.0.layer.0.normalization.running_var\",\n",
    "    \"layer4.0.conv2.weight\": \"encoder.stages.3.layers.0.layer.1.convolution.weight\",\n",
    "    \"layer4.0.bn2.weight\": \"encoder.stages.3.layers.0.layer.1.normalization.weight\",\n",
    "    \"layer4.0.bn2.bias\": \"encoder.stages.3.layers.0.layer.1.normalization.bias\",\n",
    "    \"layer4.0.bn2.running_mean\": \"encoder.stages.3.layers.0.layer.1.normalization.running_mean\",\n",
    "    \"layer4.0.bn2.running_var\": \"encoder.stages.3.layers.0.layer.1.normalization.running_var\",\n",
    "    \"layer4.0.conv3.weight\": \"encoder.stages.3.layers.0.layer.2.convolution.weight\",\n",
    "    \"layer4.0.bn3.weight\": \"encoder.stages.3.layers.0.layer.2.normalization.weight\",\n",
    "    \"layer4.0.bn3.bias\": \"encoder.stages.3.layers.0.layer.2.normalization.bias\",\n",
    "    \"layer4.0.bn3.running_mean\": \"encoder.stages.3.layers.0.layer.2.normalization.running_mean\",\n",
    "    \"layer4.0.bn3.running_var\": \"encoder.stages.3.layers.0.layer.2.normalization.running_var\",\n",
    "    \"layer4.0.downsample.0.weight\": \"encoder.stages.3.layers.0.shortcut.convolution.weight\",\n",
    "    \"layer4.0.downsample.1.weight\": \"encoder.stages.3.layers.0.shortcut.normalization.weight\",\n",
    "    \"layer4.0.downsample.1.bias\": \"encoder.stages.3.layers.0.shortcut.normalization.bias\",\n",
    "    \"layer4.0.downsample.1.running_mean\": \"encoder.stages.3.layers.0.shortcut.normalization.running_mean\",\n",
    "    \"layer4.0.downsample.1.running_var\": \"encoder.stages.3.layers.0.shortcut.normalization.running_var\",\n",
    "    \n",
    "    \"layer4.1.conv1.weight\": \"encoder.stages.3.layers.1.layer.0.convolution.weight\",\n",
    "    \"layer4.1.bn1.weight\": \"encoder.stages.3.layers.1.layer.0.normalization.weight\",\n",
    "    \"layer4.1.bn1.bias\": \"encoder.stages.3.layers.1.layer.0.normalization.bias\",\n",
    "    \"layer4.1.bn1.running_mean\": \"encoder.stages.3.layers.1.layer.0.normalization.running_mean\",\n",
    "    \"layer4.1.bn1.running_var\": \"encoder.stages.3.layers.1.layer.0.normalization.running_var\",\n",
    "    \"layer4.1.conv2.weight\": \"encoder.stages.3.layers.1.layer.1.convolution.weight\",\n",
    "    \"layer4.1.bn2.weight\": \"encoder.stages.3.layers.1.layer.1.normalization.weight\",\n",
    "    \"layer4.1.bn2.bias\": \"encoder.stages.3.layers.1.layer.1.normalization.bias\",\n",
    "    \"layer4.1.bn2.running_mean\": \"encoder.stages.3.layers.1.layer.1.normalization.running_mean\",\n",
    "    \"layer4.1.bn2.running_var\": \"encoder.stages.3.layers.1.layer.1.normalization.running_var\",\n",
    "    \"layer4.1.conv3.weight\": \"encoder.stages.3.layers.1.layer.2.convolution.weight\",\n",
    "    \"layer4.1.bn3.weight\": \"encoder.stages.3.layers.1.layer.2.normalization.weight\",\n",
    "    \"layer4.1.bn3.bias\": \"encoder.stages.3.layers.1.layer.2.normalization.bias\",\n",
    "    \"layer4.1.bn3.running_mean\": \"encoder.stages.3.layers.1.layer.2.normalization.running_mean\",\n",
    "    \"layer4.1.bn3.running_var\": \"encoder.stages.3.layers.1.layer.2.normalization.running_var\",\n",
    "    \n",
    "    \"layer4.2.conv1.weight\": \"encoder.stages.3.layers.2.layer.0.convolution.weight\",\n",
    "    \"layer4.2.bn1.weight\": \"encoder.stages.3.layers.2.layer.0.normalization.weight\",\n",
    "    \"layer4.2.bn1.bias\": \"encoder.stages.3.layers.2.layer.0.normalization.bias\",\n",
    "    \"layer4.2.bn1.running_mean\": \"encoder.stages.3.layers.2.layer.0.normalization.running_mean\",\n",
    "    \"layer4.2.bn1.running_var\": \"encoder.stages.3.layers.2.layer.0.normalization.running_var\",\n",
    "    \"layer4.2.conv2.weight\": \"encoder.stages.3.layers.2.layer.1.convolution.weight\",\n",
    "    \"layer4.2.bn2.weight\": \"encoder.stages.3.layers.2.layer.1.normalization.weight\",\n",
    "    \"layer4.2.bn2.bias\": \"encoder.stages.3.layers.2.layer.1.normalization.bias\",\n",
    "    \"layer4.2.bn2.running_mean\": \"encoder.stages.3.layers.2.layer.1.normalization.running_mean\",\n",
    "    \"layer4.2.bn2.running_var\": \"encoder.stages.3.layers.2.layer.1.normalization.running_var\",\n",
    "    \"layer4.2.conv3.weight\": \"encoder.stages.3.layers.2.layer.2.convolution.weight\",\n",
    "    \"layer4.2.bn3.weight\": \"encoder.stages.3.layers.2.layer.2.normalization.weight\",\n",
    "    \"layer4.2.bn3.bias\": \"encoder.stages.3.layers.2.layer.2.normalization.bias\",\n",
    "    \"layer4.2.bn3.running_mean\": \"encoder.stages.3.layers.2.layer.2.normalization.running_mean\",\n",
    "    \"layer4.2.bn3.running_var\": \"encoder.stages.3.layers.2.layer.2.normalization.running_var\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision_state_dict = resnet50.state_dict()\n",
    "\n",
    "mapped_state_dict = {}\n",
    "for k, v in torchvision_state_dict.items():\n",
    "    if k in layer_name_mapping:\n",
    "        mapped_state_dict[layer_name_mapping[k]] = v\n",
    "\n",
    "resnet50_hf.load_state_dict(mapped_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# resnet50_hf.save_pretrained(\"resnet50_hf\", push_to_hub=True, repo_id=\"galeio-research/nereus-sar-1\", token=os.getenv(\"HF_TOKEN\"))\n",
    "resnet50_hf.save_pretrained(\"resnet50_hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_hf.forward(torch.randn(1, 1, 256, 256)).pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"wave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/antoine/models/nereus/dino_resnet50/probing_head_resnet50_regression_wind_speed/w.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m path_w = \u001b[33m\"\u001b[39m\u001b[33m/home/antoine/models/nereus/dino_resnet50/probing_head_resnet50_regression_wind_speed/w.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m path_b = \u001b[33m\"\u001b[39m\u001b[33m/home/antoine/models/nereus/dino_resnet50/probing_head_resnet50_regression_wind_speed/b.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m w = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m b = torch.load(path_b, weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      9\u001b[39m w = torch.from_numpy(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/nereus-sar-models/lib/python3.11/site-packages/torch/serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/nereus-sar-models/lib/python3.11/site-packages/torch/serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/nereus-sar-models/lib/python3.11/site-packages/torch/serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/antoine/models/nereus/dino_resnet50/probing_head_resnet50_regression_wind_speed/w.pt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "path_w = \"/home/antoine/models/nereus/dino_resnet50/probing_head_resnet50_regression_wind_speed/w.pt\"\n",
    "path_b = \"/home/antoine/models/nereus/dino_resnet50/probing_head_resnet50_regression_wind_speed/b.pt\"\n",
    "\n",
    "w = torch.load(path_w, weights_only=False)\n",
    "b = torch.load(path_b, weights_only=False)\n",
    "\n",
    "w = torch.from_numpy(w)\n",
    "b = torch.from_numpy(b)\n",
    "\n",
    "w = w.unsqueeze(1)\n",
    "\n",
    "state_dict_head = {'weight': w.T, 'bias': b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "head = torch.nn.Linear(2048, 1)\n",
    "head.load_state_dict(state_dict_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_path = f\"linear-head_resnet50_{TASK}.pth\"\n",
    "\n",
    "torch.save(head.state_dict(), head_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TASK == \"wind\":\n",
    "    PROBLEM_TYPE = \"regression\"\n",
    "    NUM_LABELS = 1\n",
    "    LABEL2ID = {\"wind_speed\": 0}\n",
    "    ID2LABEL = {0: \"wind_speed\"}\n",
    "elif TASK == \"wave\":\n",
    "    PROBLEM_TYPE = \"regression\"\n",
    "    NUM_LABELS = 1\n",
    "    LABEL2ID = {\"wave_height\": 0}\n",
    "    ID2LABEL = {0: \"wave_height\"}\n",
    "elif TASK == \"tengeop\":\n",
    "    PROBLEM_TYPE = \"multi_label_classification\"\n",
    "    NUM_LABELS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name))                                                     Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "ResNetForImageClassification (ResNetForImageClassification)                 [1, 1]                    --\n",
       "├─ResNetModel (resnet)                                                      [1, 2048, 1, 1]           --\n",
       "│    └─ResNetEmbeddings (embedder)                                          [1, 64, 64, 64]           --\n",
       "│    │    └─ResNetConvLayer (embedder)                                      [1, 64, 128, 128]         --\n",
       "│    │    │    └─Conv2d (convolution)                                       [1, 64, 128, 128]         3,136\n",
       "│    │    │    └─BatchNorm2d (normalization)                                [1, 64, 128, 128]         128\n",
       "│    │    │    └─ReLU (activation)                                          [1, 64, 128, 128]         --\n",
       "│    │    └─MaxPool2d (pooler)                                              [1, 64, 64, 64]           --\n",
       "│    └─ResNetEncoder (encoder)                                              [1, 2048, 8, 8]           --\n",
       "│    │    └─ModuleList (stages)                                             --                        --\n",
       "│    │    │    └─ResNetStage (0)                                            [1, 256, 64, 64]          --\n",
       "│    │    │    │    └─Sequential (layers)                                   --                        --\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (0)                        [1, 256, 64, 64]          75,008\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (1)                        [1, 256, 64, 64]          70,400\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (2)                        [1, 256, 64, 64]          70,400\n",
       "│    │    │    └─ResNetStage (1)                                            [1, 512, 32, 32]          --\n",
       "│    │    │    │    └─Sequential (layers)                                   --                        --\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (0)                        [1, 512, 32, 32]          379,392\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (1)                        [1, 512, 32, 32]          280,064\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (2)                        [1, 512, 32, 32]          280,064\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (3)                        [1, 512, 32, 32]          280,064\n",
       "│    │    │    └─ResNetStage (2)                                            [1, 1024, 16, 16]         --\n",
       "│    │    │    │    └─Sequential (layers)                                   --                        --\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (0)                        [1, 1024, 16, 16]         1,512,448\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (1)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (2)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (3)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (4)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (5)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    └─ResNetStage (3)                                            [1, 2048, 8, 8]           --\n",
       "│    │    │    │    └─Sequential (layers)                                   --                        --\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (0)                        [1, 2048, 8, 8]           6,039,552\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (1)                        [1, 2048, 8, 8]           4,462,592\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (2)                        [1, 2048, 8, 8]           4,462,592\n",
       "│    └─AdaptiveAvgPool2d (pooler)                                           [1, 2048, 1, 1]           --\n",
       "├─Sequential (classifier)                                                   [1, 1]                    --\n",
       "│    └─Flatten (0)                                                          [1, 2048]                 --\n",
       "│    └─Linear (1)                                                           [1, 1]                    2,049\n",
       "=============================================================================================================================\n",
       "Total params: 23,503,809\n",
       "Trainable params: 23,503,809\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.24\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 232.26\n",
       "Params size (MB): 94.02\n",
       "Estimated Total Size (MB): 326.54\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import ResNetForImageClassification, ResNetConfig\n",
    "from torchinfo import summary\n",
    "\n",
    "config_resnet = ResNetConfig.from_pretrained(\"/home/antoine/models/nereus/dino_resnet50/resnet50_hf\")\n",
    "config_with_linear_head = ResNetConfig(hidden_size=2048, finetuning_task=TASK, num_labels=NUM_LABELS, problem_type=PROBLEM_TYPE, **config_resnet.to_diff_dict())\n",
    "nereus = ResNetForImageClassification(config_with_linear_head)\n",
    "\n",
    "summary(nereus, input_size=(1, 1, 256, 256), row_settings=[\"var_names\"], depth=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nereus.resnet.from_pretrained(\"/home/antoine/models/nereus/dino_resnet50/resnet50_hf\")\n",
    "state_dict_head = torch.load(f\"/home/antoine/models/nereus/dino_resnet50/linear-head_resnet50_{TASK}.weights.pth\")\n",
    "nereus.classifier[1].load_state_dict(state_dict_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 256, 256).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([tensor([[13.1773]], device='cuda:0')])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = nereus.forward(x)\n",
    "outputs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 94.3M/94.3M [00:02<00:00, 32.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/galeio-research/nereus-sar-1-wave/commit/a9c9ffe6acd725bec9bdc179a262215aa8b96e91', commit_message='Upload ResNetForImageClassification', commit_description='', oid='a9c9ffe6acd725bec9bdc179a262215aa8b96e91', pr_url=None, repo_url=RepoUrl('https://huggingface.co/galeio-research/nereus-sar-1-wave', endpoint='https://huggingface.co', repo_type='model', repo_id='galeio-research/nereus-sar-1-wave'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nereus.push_to_hub(f\"galeio-research/nereus-sar-1-{TASK}\",private=True, token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([tensor([[224.4390]], device='cuda:0')])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "nereus = AutoModelForImageClassification.from_pretrained(f\"galeio-research/nereus-sar-1-{TASK}\", token=os.environ['HF_TOKEN']).to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = nereus(x)\n",
    "outputs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNetForImageClassification' object has no attribute 'finetuning_task'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[243]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mnereus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinetuning_task\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/envs/nereus-sar-models/lib/python3.11/site-packages/torch/nn/modules/module.py:1928\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1926\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1927\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1928\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1929\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1930\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'ResNetForImageClassification' object has no attribute 'finetuning_task'"
     ]
    }
   ],
   "source": [
    "nereus.finetuning_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name))                                                     Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "ResNetForImageClassification (ResNetForImageClassification)                 [1, 1]                    --\n",
       "├─ResNetModel (resnet)                                                      [1, 2048, 1, 1]           --\n",
       "│    └─ResNetEmbeddings (embedder)                                          [1, 64, 64, 64]           --\n",
       "│    │    └─ResNetConvLayer (embedder)                                      [1, 64, 128, 128]         --\n",
       "│    │    │    └─Conv2d (convolution)                                       [1, 64, 128, 128]         3,136\n",
       "│    │    │    └─BatchNorm2d (normalization)                                [1, 64, 128, 128]         128\n",
       "│    │    │    └─ReLU (activation)                                          [1, 64, 128, 128]         --\n",
       "│    │    └─MaxPool2d (pooler)                                              [1, 64, 64, 64]           --\n",
       "│    └─ResNetEncoder (encoder)                                              [1, 2048, 8, 8]           --\n",
       "│    │    └─ModuleList (stages)                                             --                        --\n",
       "│    │    │    └─ResNetStage (0)                                            [1, 256, 64, 64]          --\n",
       "│    │    │    │    └─Sequential (layers)                                   --                        --\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (0)                        [1, 256, 64, 64]          75,008\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (1)                        [1, 256, 64, 64]          70,400\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (2)                        [1, 256, 64, 64]          70,400\n",
       "│    │    │    └─ResNetStage (1)                                            [1, 512, 32, 32]          --\n",
       "│    │    │    │    └─Sequential (layers)                                   --                        --\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (0)                        [1, 512, 32, 32]          379,392\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (1)                        [1, 512, 32, 32]          280,064\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (2)                        [1, 512, 32, 32]          280,064\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (3)                        [1, 512, 32, 32]          280,064\n",
       "│    │    │    └─ResNetStage (2)                                            [1, 1024, 16, 16]         --\n",
       "│    │    │    │    └─Sequential (layers)                                   --                        --\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (0)                        [1, 1024, 16, 16]         1,512,448\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (1)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (2)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (3)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (4)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (5)                        [1, 1024, 16, 16]         1,117,184\n",
       "│    │    │    └─ResNetStage (3)                                            [1, 2048, 8, 8]           --\n",
       "│    │    │    │    └─Sequential (layers)                                   --                        --\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (0)                        [1, 2048, 8, 8]           6,039,552\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (1)                        [1, 2048, 8, 8]           4,462,592\n",
       "│    │    │    │    │    └─ResNetBottleNeckLayer (2)                        [1, 2048, 8, 8]           4,462,592\n",
       "│    └─AdaptiveAvgPool2d (pooler)                                           [1, 2048, 1, 1]           --\n",
       "├─Sequential (classifier)                                                   [1, 1]                    --\n",
       "│    └─Flatten (0)                                                          [1, 2048]                 --\n",
       "│    └─Linear (1)                                                           [1, 1]                    2,049\n",
       "=============================================================================================================================\n",
       "Total params: 23,503,809\n",
       "Trainable params: 23,503,809\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.24\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 232.26\n",
       "Params size (MB): 94.02\n",
       "Estimated Total Size (MB): 326.54\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(nereus, input_size=(1, 1, 256, 256), row_settings=[\"var_names\"], depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nereus-sar-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
